{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook Covers:\n",
    "1. Creation of Inbuilt tools\n",
    "2. Creation of Custom tools\n",
    "3. Creation of Agents and AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Arxiv Research\n",
    "## Tools Creation\n",
    "\n",
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation Of Inbuilt Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wikipedia wrapper will use the Wikipedia API to conduct searches and fetch page summaries\n",
    "# By default, it will return the page summaries of the top-k results. It limits the Document content by doc_content_chars_max.\n",
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=1,doc_content_chars_max=250)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of Custom Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000013E74E6F4D0>, search_kwargs={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size = 1000,chunk_overlap=200).split_documents(docs)\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama3\",\n",
    ")\n",
    "vectordb = FAISS.from_documents(documents,embeddings)\n",
    "retriever = vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith-search'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool = create_retriever_tool(retriever,\"langsmith-search\",\"Search any information about langsmith\")\n",
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run all this tools with Agents and LLM Models\n",
    "#Tools, LLM-->AgentExecutor\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm = ChatGroq(groq_api_key=groq_api_key,model_name = \"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Template\n",
    "from langchain import hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of Agents and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm,tools,prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000013E628144A0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000013E628144A0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000013E7F1EC6E0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000013E7F1ED220>, model_name='Llama3-8b-8192', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'wikipedia', 'description': 'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'query to look up on wikipedia', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith-search', 'description': 'Search any information about langsmith', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent executor\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith-search` with `{'query': 'What is Langsmith?'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | 🦜️🛠️ LangSmith\n",
      "\n",
      "4. Log your first trace​\n",
      "LangSmith + LangChain OSSYou don't need to use the LangSmith SDK directly if your application is built on LangChain/LangGraph (either Python and JS).See the how-to guide for tracing with LangChain here.\n",
      "We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "how to use traceable(). See more on the Annotate code for tracing page.\n",
      "\n",
      "View a sample output trace.\n",
      "Learn more about tracing in the observability tutorials, conceptual guide and how-to guides.\n",
      "\n",
      "Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n",
      "and explore the results of your evaluation.\n",
      "Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\u001b[0m\u001b[32;1m\u001b[1;3mBased on the output, it appears that Langsmith is a platform that allows users to log traces and evaluate their applications. It provides multiple ways to log traces and offers various guides and resources to help users get started.\n",
      "\n",
      "Here's a summary of what Langsmith offers:\n",
      "\n",
      "* Tracing: Langsmith allows users to log traces using the `traceable()` function, which can be used with LangChain/LangGraph applications.\n",
      "* Evaluation: Langsmith provides a way to evaluate the results of tracing, allowing users to access the results of their evaluation and explore the Langsmith experiments UI.\n",
      "* Resources: Langsmith offers various guides, tutorials, and conceptual guides to help users understand how to use the platform and get the most out of it.\n",
      "\n",
      "Overall, Langsmith seems to be a tool for developers and researchers to understand and improve the performance of their applications.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"Based on the output, it appears that Langsmith is a platform that allows users to log traces and evaluate their applications. It provides multiple ways to log traces and offers various guides and resources to help users get started.\\n\\nHere's a summary of what Langsmith offers:\\n\\n* Tracing: Langsmith allows users to log traces using the `traceable()` function, which can be used with LangChain/LangGraph applications.\\n* Evaluation: Langsmith provides a way to evaluate the results of tracing, allowing users to access the results of their evaluation and explore the Langsmith experiments UI.\\n* Resources: Langsmith offers various guides, tutorials, and conceptual guides to help users understand how to use the platform and get the most out of it.\\n\\nOverall, Langsmith seems to be a tool for developers and researchers to understand and improve the performance of their applications.\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNLP (Natural Language Processing) and Machine Learning are two interconnected fields that are often used together, but they are distinct:\n",
      "\n",
      "NLP (Natural Language Processing) is a subfield of Artificial Intelligence (AI) that deals with the interaction between computers and humans in natural language. It focuses on enabling computers to understand, interpret, and generate human language, such as text or speech. NLP involves a range of tasks, including:\n",
      "\n",
      "1. Tokenization: breaking text into individual words or tokens\n",
      "2. Part-of-speech tagging: identifying the grammatical categories of words (e.g., noun, verb, adjective)\n",
      "3. Named entity recognition: identifying specific entities (e.g., names, locations, organizations)\n",
      "4. Sentiment analysis: determining the emotional tone or sentiment of text\n",
      "5. Language translation: translating text from one language to another\n",
      "\n",
      "NLP is a key component of many AI applications, such as chatbots, voice assistants, and language translation software.\n",
      "\n",
      "Machine Learning (ML) is a subset of AI that involves training algorithms to learn from data and make predictions or take actions. ML is a broader field that encompasses many techniques, including supervised, unsupervised, and reinforcement learning.\n",
      "\n",
      "In the context of NLP, Machine Learning is used to develop models that can perform various NLP tasks, such as:\n",
      "\n",
      "1. Text classification: classifying text into categories (e.g., spam vs. non-spam emails)\n",
      "2. Sentiment analysis: predicting the sentiment of text\n",
      "3. Language modeling: predicting the next word in a sequence\n",
      "4. Machine translation: translating text from one language to another\n",
      "\n",
      "Machine Learning algorithms are used to analyze large amounts of NLP data, identify patterns, and make predictions. For example, a machine learning algorithm might be trained on a dataset of labeled text to predict the sentiment of new, unseen text.\n",
      "\n",
      "Key differences between NLP and Machine Learning:\n",
      "\n",
      "1. Focus: NLP focuses on understanding and generating human language, while Machine Learning focuses on developing algorithms that can learn from data.\n",
      "2. Scope: NLP is a subfield of AI, while Machine Learning is a broader field that encompasses many AI applications.\n",
      "3. Techniques: NLP involves tasks like tokenization, part-of-speech tagging, and named entity recognition, while Machine Learning involves techniques like supervised, unsupervised, and reinforcement learning.\n",
      "\n",
      "In summary, NLP is a subfield of AI that focuses on understanding and generating human language, while Machine Learning is a broader field that encompasses many AI applications, including NLP.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is difference between nlp and machine learning',\n",
       " 'output': 'NLP (Natural Language Processing) and Machine Learning are two interconnected fields that are often used together, but they are distinct:\\n\\nNLP (Natural Language Processing) is a subfield of Artificial Intelligence (AI) that deals with the interaction between computers and humans in natural language. It focuses on enabling computers to understand, interpret, and generate human language, such as text or speech. NLP involves a range of tasks, including:\\n\\n1. Tokenization: breaking text into individual words or tokens\\n2. Part-of-speech tagging: identifying the grammatical categories of words (e.g., noun, verb, adjective)\\n3. Named entity recognition: identifying specific entities (e.g., names, locations, organizations)\\n4. Sentiment analysis: determining the emotional tone or sentiment of text\\n5. Language translation: translating text from one language to another\\n\\nNLP is a key component of many AI applications, such as chatbots, voice assistants, and language translation software.\\n\\nMachine Learning (ML) is a subset of AI that involves training algorithms to learn from data and make predictions or take actions. ML is a broader field that encompasses many techniques, including supervised, unsupervised, and reinforcement learning.\\n\\nIn the context of NLP, Machine Learning is used to develop models that can perform various NLP tasks, such as:\\n\\n1. Text classification: classifying text into categories (e.g., spam vs. non-spam emails)\\n2. Sentiment analysis: predicting the sentiment of text\\n3. Language modeling: predicting the next word in a sequence\\n4. Machine translation: translating text from one language to another\\n\\nMachine Learning algorithms are used to analyze large amounts of NLP data, identify patterns, and make predictions. For example, a machine learning algorithm might be trained on a dataset of labeled text to predict the sentiment of new, unseen text.\\n\\nKey differences between NLP and Machine Learning:\\n\\n1. Focus: NLP focuses on understanding and generating human language, while Machine Learning focuses on developing algorithms that can learn from data.\\n2. Scope: NLP is a subfield of AI, while Machine Learning is a broader field that encompasses many AI applications.\\n3. Techniques: NLP involves tasks like tokenization, part-of-speech tagging, and named entity recognition, while Machine Learning involves techniques like supervised, unsupervised, and reinforcement learning.\\n\\nIn summary, NLP is a subfield of AI that focuses on understanding and generating human language, while Machine Learning is a broader field that encompasses many AI applications, including NLP.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what is difference between nlp and machine learning\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': '1706.03762'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on c\u001b[0m\u001b[32;1m\u001b[1;3mBased on the output provided by the user, I can see that the tool call yielded information about the paper with ID \"1706.03762\". The paper is titled \"Attention Is All You Need\" and was published on 2023-08-02. It appears to be a research paper in the field of natural language processing and machine learning.\n",
      "\n",
      "Here's a direct response without using any additional tools:\n",
      "\n",
      "The paper \"Attention Is All You Need\" by Ashish Vaswani et al. introduces a new approach to sequence transduction that relies solely on self-attention mechanisms, eliminating the need for traditional recurrent neural network (RNN) or convolutional neural network (CNN) structures.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"what's the paper 1706.03762 is all about?\",\n",
       " 'output': 'Based on the output provided by the user, I can see that the tool call yielded information about the paper with ID \"1706.03762\". The paper is titled \"Attention Is All You Need\" and was published on 2023-08-02. It appears to be a research paper in the field of natural language processing and machine learning.\\n\\nHere\\'s a direct response without using any additional tools:\\n\\nThe paper \"Attention Is All You Need\" by Ashish Vaswani et al. introduces a new approach to sequence transduction that relies solely on self-attention mechanisms, eliminating the need for traditional recurrent neural network (RNN) or convolutional neural network (CNN) structures.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"what's the paper 1706.03762 is all about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
